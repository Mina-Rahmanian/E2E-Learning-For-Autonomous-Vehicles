{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E2E learning- MS- Mina Rahmanian.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgeRRw1nGTeO",
        "colab_type": "text"
      },
      "source": [
        "# E2E Deep Learning for AV Control Using Udacity's Car Simulator Environment\n",
        "\n",
        "## Mina Rahmanian Shahri - 20137470\n",
        "\n",
        "### Master of Queen's University"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wwgT0Mk-EPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhNfPAQlHfth",
        "colab_type": "text"
      },
      "source": [
        "## Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDJu6Rqe0dq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K0MfgTp0d4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall keras\n",
        "!pip install Keras==2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf3oI4aY0eCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiOFv7NS0eKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -c 'import keras; print(keras.__version__)'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGgGEWfbZW0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install imgaug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSnupDY9Hqvo",
        "colab_type": "text"
      },
      "source": [
        "## Importing Python libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB5iqSF6OMn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import gc\n",
        "import ntpath\n",
        "import json\n",
        "from imgaug import augmenters as iaa\n",
        "import skimage.transform as sktransform\n",
        "\n",
        "\n",
        "# keras\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Convolution2D, MaxPooling2D,Dense,Flatten,Dropout\n",
        "from keras import backend as K\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kgiqbc0k9Tx",
        "colab_type": "text"
      },
      "source": [
        "Unzip Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3HxczT-Dklq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip '/content/gdrive/My Drive/car/data.zip' -d '/content/gdrive/My Drive/car'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k-Rju6PHFZc",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqpCQhqDZoho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Columns: ['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n",
        "\n",
        "\n",
        "dataload = '/content/gdrive/My Drive/car/data'\n",
        "\n",
        "data_dir = pd.read_csv(os.path.join(dataload, 'driving_log.csv'))\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "\n",
        "data_dir.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JDQc_jnaAhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def path_leaf(path):\n",
        "  head, tail = ntpath.split(path)\n",
        "  return tail\n",
        "\n",
        "\n",
        "data_dir['center'] = data_dir['center'].apply(path_leaf)\n",
        "data_dir['left'] = data_dir['left'].apply(path_leaf)\n",
        "data_dir['right'] = data_dir['right'].apply(path_leaf)\n",
        "\n",
        "\n",
        "data_dir.head(200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7Hzm2rg7fTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtH5kZaxlUUu",
        "colab_type": "text"
      },
      "source": [
        "## Signal with `savgol_filter`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDJyYg-A7ipz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Smooth data signal with `savgol_filter`\n",
        "import scipy\n",
        "from scipy import signal\n",
        "\n",
        "\n",
        "# data_dir[\"steering\"] = signal.savgol_filter(data_dir[\"steering\"].values.tolist(), 43, 17)\n",
        "data_dir[\"steering\"] = signal.savgol_filter(data_dir[\"steering\"].values.tolist(), 51, 11)\n",
        "data_dir[\"speed\"] = signal.savgol_filter(data_dir[\"speed\"].values.tolist(), 25, 15)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTEVmRcYz_aX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir.head(200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDbpO6f96JaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUZWAmRxP-e5",
        "colab_type": "text"
      },
      "source": [
        "## Dataset distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxLJTP6fc66u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data distribution\n",
        "new=data_dir['steering']\n",
        "steer=list(new)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(14,8))\n",
        "x = [range(len(steer))]\n",
        "x = np.squeeze(np.asarray(x))\n",
        "y = np.asarray(steer)\n",
        "\n",
        "\n",
        "# plot\n",
        "plt.xlim(0,8000)\n",
        "plt.title('Data Distribution', fontsize=22)\n",
        "plt.xlabel('Frames', fontsize=16)\n",
        "plt.ylabel('Steering Angle', fontsize=16)\n",
        "plt.plot(x,y, 'g', linewidth=0.4)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wykJhnl5MWno",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Balance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7ZNuQTqaFjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize data\n",
        "num_bins = 25\n",
        "samples_per_bin = 180  #400  #200\n",
        "\n",
        "hist, bins = np.histogram(data_dir['steering'], num_bins)\n",
        "center = (bins[:-1]+ bins[1:]) * 0.5\n",
        "\n",
        "# Plot\n",
        "fig= plt.figure(figsize=(10,7))\n",
        "plt.bar(center, hist, width=0.05)\n",
        "plt.plot((np.min(data_dir['steering']), np.max(data_dir['steering'])), (samples_per_bin, samples_per_bin),'r')\n",
        "plt.title('Before balance control', fontsize=22)\n",
        "plt.xlabel('steering angle', fontsize=15)\n",
        "plt.ylabel('counts', fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2JE8U2kaWoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data_dir\n",
        "print('total data: ',len(data))\n",
        "\n",
        "# Make list of indices to remove\n",
        "remove_list=[]\n",
        "\n",
        "for j in range(num_bins):\n",
        "    list_=[]\n",
        "    for i in range(len(data['steering'])):\n",
        "        if data['steering'][i] > bins[j] and data['steering'][i] <= bins[j+1]:\n",
        "            list_.append(i)\n",
        "    list_=shuffle(list_)\n",
        "    list_=list_[samples_per_bin:]\n",
        "    remove_list.extend(list_)\n",
        "\n",
        "\n",
        "# Remove from extras from list   \n",
        "print('removed data: ',len(remove_list))\n",
        "data.drop(data.index[remove_list],inplace=True)\n",
        "print('remainig data: ',len(data))\n",
        "\n",
        "\n",
        "# Plot\n",
        "hist, _ = np.histogram(data['steering'],(num_bins))\n",
        "\n",
        "fig= plt.figure(figsize=(10,7))\n",
        "plt.bar(center,hist,width=0.05)\n",
        "plt.plot((np.min(data['steering']),np.max(data['steering'])),(samples_per_bin,samples_per_bin),'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwnn-AzZM-79",
        "colab_type": "text"
      },
      "source": [
        "# Display the balance of each columns of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkFu08SwSc6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "balanced = pd.DataFrame()   # Balanced dataset\n",
        "bins = 1000                 # N of bins\n",
        "bin_n = 200                 # N of examples to include in each bin (at most)\n",
        "\n",
        "start = 0\n",
        "for end in np.linspace(0, 1, num=bins):  \n",
        "    data_range = data[(np.absolute(data.steering) >= start) & (np.absolute(data.steering) < end)]\n",
        "    range_n = min(bin_n, data_range.shape[0])\n",
        "    balanced = pd.concat([balanced, data_range.sample(range_n)])\n",
        "    start = end\n",
        "    \n",
        "balanced.to_csv('/content/gdrive/My Drive/car/data/driving_log.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "balanced.plot.hist(grid=True, bins=200, rwidth=3.5)\n",
        "\n",
        "fig = plt.figure(figsize = (12,12))\n",
        "ax = fig.gca()\n",
        "balanced.hist(ax=ax)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxFE8AeBOACl",
        "colab_type": "text"
      },
      "source": [
        "# Create Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro0vGP4maWw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(data.iloc[1])\n",
        "\n",
        "# Get images and measurements from left/right camera\n",
        "# Get images and steering data into arrays\n",
        "def load_img_steering(datadir, df):\n",
        "  image_path = []\n",
        "  steering = []\n",
        "\n",
        "  for i in range(len(data)):\n",
        "    indexed_data = data.iloc[i]\n",
        "    center, left, right = indexed_data[0], indexed_data[1], indexed_data[2]\n",
        "    image_path.append(os.path.join(datadir, center.strip()))\n",
        "    steering.append(float(indexed_data[3]))\n",
        "\n",
        "    # left image append\n",
        "    image_path.append(os.path.join(datadir,left.strip()))\n",
        "    steering.append(float(indexed_data[3])+ 0.25) # 0.15\n",
        "    \n",
        "    # right image append\n",
        "    image_path.append(os.path.join(datadir,right.strip()))\n",
        "    steering.append(float(indexed_data[3])- 0.25) # 0.15\n",
        "\n",
        "\n",
        "  image_paths = np.asarray(image_path)\n",
        "  steerings = np.asarray(steering)\n",
        "  return image_paths, steerings\n",
        " \n",
        " \n",
        "image_paths, steerings = load_img_steering(dataload + '/IMG', data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VloJosEqOaLk",
        "colab_type": "text"
      },
      "source": [
        "## Randomly display the Images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCx-1A2X-u3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "im1 = image_paths[random.randint(0, 1000)]\n",
        "im2 = image_paths[random.randint(0, 1000)]\n",
        "im3 = image_paths[random.randint(0, 1000)]\n",
        "\n",
        "imshow1= mpimg.imread(im1)\n",
        "imshow2= mpimg.imread(im2)\n",
        "imshow3= mpimg.imread(im3)\n",
        "\n",
        "fig, axs = plt.subplots(1,3, figsize=(20, 10))\n",
        "\n",
        "axs[0].imshow(imshow1)\n",
        "axs[0].set_title('Path 1 ')\n",
        "axs[1].imshow(imshow2)\n",
        "axs[1].set_title('Path 2 ')\n",
        "axs[2].imshow(imshow3)\n",
        "axs[2].set_title('Path 3 ')\n",
        "\n",
        "\n",
        "h1, im1= ntpath.split(im1)\n",
        "h2, im2= ntpath.split(im2)\n",
        "h3, im3= ntpath.split(im3)\n",
        "\n",
        "\n",
        "print('path 1 = {}'.format (im1)) \n",
        "print('path 2 = {}'.format (im2))\n",
        "print('path 3 = {} \\n\\n'.format (im3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKxA942VWJ6V",
        "colab_type": "text"
      },
      "source": [
        " Data Selection:\n",
        "## Spliting Training & Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi_NleTtaW05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(image_paths, steerings, test_size=0.25, random_state=6)\n",
        "print('Training Samples: {}\\nValid Samples: {}'.format(len(X_train), len(X_valid)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4_w7o8CaW4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig,axes=plt.subplots(1,2,figsize=(18,7))\n",
        "\n",
        "axes[0].hist(Y_train,bins=num_bins,width=0.05,color='royalblue')\n",
        "axes[0].set_title('Trainig Set')\n",
        "\n",
        "axes[1].hist(Y_valid,bins=num_bins,width=0.05,color='tomato')\n",
        "axes[1].set_title('Validation Set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAG1_OthWmCp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Data Augmentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJFqAhSbXCLx",
        "colab_type": "text"
      },
      "source": [
        "Zoom Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q6_qL3EcDZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get any image\n",
        "def zoom(image):\n",
        "  zoom = iaa.Affine(scale=(1, 1.3))\n",
        "  image = zoom.augment_image(image)\n",
        "  \n",
        "  return image\n",
        "\n",
        "\n",
        "# Zoom random images\n",
        "# Compare original and zoom image\n",
        "image = image_paths[random.randint(0, 500)]\n",
        "original_image = mpimg.imread(image)\n",
        "zoomed_image = zoom(original_image)\n",
        " \n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        " \n",
        "axs[0].imshow(original_image)\n",
        "axs[0].set_title('Original Image')\n",
        " \n",
        "axs[1].imshow(zoomed_image)\n",
        "axs[1].set_title('Zoomed Image')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkoq5ynmXu7Y",
        "colab_type": "text"
      },
      "source": [
        "Translational Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGmIH-jccDvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get any image\n",
        "def pan(image):\n",
        "  pan = iaa.Affine(translate_percent= {\"x\" : (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
        "  image = pan.augment_image(image)\n",
        "  return image\n",
        "\n",
        "# Translating random images\n",
        "# Compare original and panned/Translational image\n",
        "image = image_paths[random.randint(0, 500)]\n",
        "original_image = mpimg.imread(image)\n",
        "panned_image = pan(original_image)\n",
        " \n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        " \n",
        "axs[0].imshow(original_image)\n",
        "axs[0].set_title('Original Image')\n",
        " \n",
        "axs[1].imshow(panned_image)\n",
        "axs[1].set_title('Panned Image')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZQoXhkhYRr9",
        "colab_type": "text"
      },
      "source": [
        "Brightness Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO7Qk5C5cdBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get any image\n",
        "def img_random_brightness(image):\n",
        "    brightness = iaa.Multiply((0.2, 1.2))\n",
        "    image = brightness.augment_image(image)\n",
        "    return image\n",
        "\n",
        "# Altering the brightness of random images\n",
        "# Compare original and brightness image\n",
        "image = image_paths[random.randint(0, 500)]\n",
        "original_image = mpimg.imread(image)\n",
        "brightness_altered_image = img_random_brightness(original_image)\n",
        " \n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        " \n",
        "axs[0].imshow(original_image)\n",
        "axs[0].set_title('Original Image')\n",
        " \n",
        "axs[1].imshow(brightness_altered_image)\n",
        "axs[1].set_title('Brightness altered image ')    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5gZZZo6YhCH",
        "colab_type": "text"
      },
      "source": [
        "Flipping Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucp6EZZ7cdUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get any image\n",
        "def img_random_flip(image, steering_angle):\n",
        "    image = cv2.flip(image,1)\n",
        "    steering_angle = -steering_angle\n",
        "    \n",
        "    return image, steering_angle\n",
        "\n",
        "\n",
        "# Randomly flipping the input image horizontaly, with steering angle adjustment.\n",
        "# Compare original and Flipping image\n",
        "random_index = random.randint(0, 500)\n",
        "image = image_paths[random_index]\n",
        "steering_angle = steerings[random_index]\n",
        " \n",
        " \n",
        "original_image = mpimg.imread(image)\n",
        "flipped_image, flipped_steering_angle = img_random_flip(original_image, steering_angle)\n",
        " \n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        " \n",
        "axs[0].imshow(original_image)\n",
        "axs[0].set_title('Original Image - ' + 'Steering Angle: ' + str(steering_angle))\n",
        " \n",
        "axs[1].imshow(flipped_image)\n",
        "axs[1].set_title('Flipped Image - ' + 'Steering Angle: ' + str(flipped_steering_angle))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ib1NjXd3Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate an augumented image and adjust the associated steering angle.\n",
        "def random_augment(image, steering_angle):\n",
        "\n",
        "    image = mpimg.imread(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "      image = pan(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "      image = zoom(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "      image = img_random_brightness(image)\n",
        "    if np.random.rand() < 0.5:\n",
        "      image, steering_angle = img_random_flip(image, steering_angle)\n",
        "    \n",
        "    \n",
        "    return image, steering_angle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkpc7dOPd3Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ncol = 2\n",
        "nrow = 10\n",
        " \n",
        "fig, axs = plt.subplots(nrow, ncol, figsize=(15, 70))\n",
        "fig.tight_layout()\n",
        "\n",
        "# Compare some original and augumented images \n",
        "for i in range(10):\n",
        "  randnum = random.randint(0, len(image_paths) - 1)\n",
        "  random_image = image_paths[randnum]\n",
        "  random_steering = steerings[randnum]\n",
        "    \n",
        "  original_image = mpimg.imread(random_image)\n",
        "  augmented_image, steering = random_augment(random_image, random_steering)\n",
        "    \n",
        "  axs[i][0].imshow(original_image)\n",
        "  axs[i][0].set_title(\"Original Image\")\n",
        "  \n",
        "  axs[i][1].imshow(augmented_image)\n",
        "  axs[i][1].set_title(\"Augmented Image\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvIN62m9bD_D",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHGd5Xcgd3UN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_preprocess(img):\n",
        "\n",
        "    # Cropping the image\n",
        "    img = img[60:135,:,:]\n",
        "    # Converting the image to the YUV color space.\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
        "    img = cv2.GaussianBlur(img,  (3, 3), 0)\n",
        "    # Resizing the image to (66 * 200), the image size that the model expects.\n",
        "    img = cv2.resize(img, (200, 66))\n",
        "    img = img/255\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0yjoYREd3XS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = image_paths[100]\n",
        "original_image = mpimg.imread(image)\n",
        "preprocessed_image = img_preprocess(original_image)\n",
        " \n",
        "# Compare original and preprocessing image\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        "axs[0].imshow(original_image)\n",
        "axs[0].set_title('Original Image')\n",
        "axs[1].imshow(preprocessed_image)\n",
        "axs[1].set_title('Preprocessed Image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i97Xya0ed-bD",
        "colab_type": "text"
      },
      "source": [
        "### Generate and Compare an Augumentation and Preprocessing image in Training & Validation separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NQyeiPmd3ak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(image_paths, steering_ang, batch_size, istraining):\n",
        "\n",
        "# batch_size =100\n",
        "\n",
        "  while True:\n",
        "    batch_img = []\n",
        "    batch_steering = []\n",
        "    \n",
        "    for i in range(batch_size):\n",
        "      random_index = random.randint(0, len(image_paths) - 1)\n",
        "      \n",
        "      if istraining:\n",
        "        im, steering = random_augment(image_paths[random_index], steering_ang[random_index])\n",
        "     \n",
        "      else:\n",
        "        im = mpimg.imread(image_paths[random_index])\n",
        "        steering = steering_ang[random_index]\n",
        "      \n",
        "      im = img_preprocess(im)\n",
        "      batch_img.append(im)\n",
        "      batch_steering.append(steering)\n",
        "    yield (np.asarray(batch_img), np.asarray(batch_steering))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClmwCOsNfB_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_gen, y_train_gen = next(batch_generator(X_train, Y_train, 1, 1))\n",
        "x_valid_gen, y_valid_gen = next(batch_generator(X_valid, Y_valid, 1, 0))\n",
        " \n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        " \n",
        "axs[0].imshow(x_train_gen[0])\n",
        "axs[0].set_title('Training Image')\n",
        " \n",
        "axs[1].imshow(x_valid_gen[0])\n",
        "axs[1].set_title('Validation Image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CHcL51ygdqc",
        "colab_type": "text"
      },
      "source": [
        "# Define models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugH7Jh87fCH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "\n",
        "## Define Swish activation function\n",
        "\n",
        "#t = -1.0\n",
        "#def ftswish(x):\n",
        "#  return K.maximum(t, K.relu(x)*K.sigmoid(x) + t)\n",
        "\n",
        "##########################################################\n",
        "\n",
        "\n",
        "def nvidia_model():\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(24, 5, 5, subsample=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "  model.add(Convolution2D(36, 5, 5, subsample=(2, 2), activation='elu'))\n",
        "  model.add(Convolution2D(48, 5, 5, subsample=(2, 2), activation='elu'))\n",
        "  model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
        "  \n",
        "  model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
        "#   model.add(Dropout(0.5))\n",
        "  \n",
        "  \n",
        "  model.add(Flatten())\n",
        "  \n",
        "  model.add(Dense(100, activation = 'elu'))\n",
        "#   model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(50, activation = 'elu'))\n",
        "#   model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(10, activation = 'elu'))\n",
        "#   model.add(Dropout(0.5))\n",
        " \n",
        "  model.add(Dense(1))\n",
        "  \n",
        "  # Define optimizer and criterion\n",
        "  optimizer = Adam(lr=1e-3)\n",
        "  model.compile(loss='mse', optimizer=optimizer, metrics=['mean_squared_error'])\n",
        "  return model\n",
        "\n",
        "\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOYgT6PoCcEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Lambda, Conv2D, MaxPooling2D, Dropout, Dense, Flatten\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import csv\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Cropping2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Lambda, Activation\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Cropping2D\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from keras.constraints import max_norm\n",
        "from keras import backend as K\n",
        "from keras.backend import sigmoid \n",
        "from keras.utils.generic_utils import get_custom_objects \n",
        "from keras.layers import Activation \n",
        "from keras import backend as K\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications import VGG16\n",
        "\n",
        "\n",
        "\n",
        "def nvidia_model2():\n",
        "    model = Sequential()\n",
        "    model.add(Lambda(lambda x: x/255.0 -0.5, input_shape=(66, 200, 3))) # normalization\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(24, 5, 5, activation= 'relu', subsample=(2, 2), kernel_regularizer=regularizers.l2(0.001), kernel_constraint=max_norm(3), bias_constraint=max_norm(3)))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(36, 5, 5, activation='relu', subsample=(2, 2), kernel_regularizer=regularizers.l2(0.001), kernel_constraint=max_norm(3), bias_constraint=max_norm(3)))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(48, 5, 5, activation='relu', subsample=(2, 2), kernel_regularizer=regularizers.l2(0.001), kernel_constraint=max_norm(3), bias_constraint=max_norm(3)))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, 3, 3, activation='relu', kernel_regularizer=regularizers.l2(0.001), kernel_constraint=max_norm(3), bias_constraint=max_norm(3))) \n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, 3, 3, activation='relu', kernel_regularizer=regularizers.l2(0.001), kernel_constraint=max_norm(3), bias_constraint=max_norm(3))) \n",
        "\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "\n",
        "\n",
        "    model.add(Dense(1))\n",
        "\n",
        " \n",
        "    # Define optimizer and criterion\n",
        "    optimizer = Adam(lr=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer, metrics=['mean_squared_error'])\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw7CKLD9hdY5",
        "colab_type": "text"
      },
      "source": [
        " I can not try below cell because of computational limitation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbBZfLVfzx5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "\n",
        "# vgg = VGG16(weights='imagenet', include_top=False, input_shape=(66, 200, 3))\n",
        "\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(66, 200, 3))\n",
        "\n",
        "for layer in resnet.layers[:-4]:\n",
        "    layer.trainable = False\n",
        " \n",
        "for layer in resnet.layers:\n",
        "    print(layer, layer.trainable)\n",
        "\n",
        "\n",
        "def nvidia_model3():\n",
        "    model = Sequential()\n",
        "    #model.add(Lambda(lambda x: x / 127.5 - 1., input_shape=(66, 200, 3))) # normalization\n",
        "\n",
        "    model.add(resnet)\n",
        "    # model.add(vgg)\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "\n",
        "\n",
        "    model.add(Dense(1))\n",
        "\n",
        "\n",
        "    # Define optimizer and criterion\n",
        "    optimizer = Adam(lr=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer, metrics=['mean_squared_error'])\n",
        "    return model\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmstvSIwh8mf",
        "colab_type": "text"
      },
      "source": [
        "# Architectures of Model/Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v68N4xPfCFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=nvidia_model2()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL-56rNgiYOg",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P2c47iCfCCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "filepath=\"E2E_cnn.hdf5\"\n",
        "\n",
        "\n",
        "checkpoint1 = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "#checkpoint2 = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=5)\n",
        "callbacks_list = [checkpoint1]\n",
        "\n",
        "# Set callback functions to early stop training and save the best model so far\n",
        "#callbacks_list = [checkpoint1, checkpoint2]\n",
        "\n",
        "\n",
        "# Train Network\n",
        "history = model.fit_generator(batch_generator(X_train, Y_train, 100, 1),\n",
        "                                  steps_per_epoch=400, \n",
        "                                  epochs=50,\n",
        "                                  validation_data=batch_generator(X_valid, Y_valid, 100, 0),\n",
        "                                  validation_steps=300,\n",
        "                                  verbose=1,\n",
        "                                  shuffle = 1,\n",
        "                                  callbacks = callbacks_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uye6VFlDidnX",
        "colab_type": "text"
      },
      "source": [
        "## Plot Training Loss vs Validation Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApK1LkB2fB86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fig= plt.figure(figsize=(12,7))\n",
        "\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.xlabel(\"Iterations/Epoch\")\n",
        "plt.plot(history.history['loss'], 'b')\n",
        "plt.plot(history.history['val_loss'], 'g-.')\n",
        "plt.legend(['Training Loss','Validation Loss'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QghCQuZ1ilCQ",
        "colab_type": "text"
      },
      "source": [
        "## Plot Training MSE vs Validation MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVxlMdXT3ekp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fig= plt.figure(figsize=(12,7))\n",
        "plt.title(\"Training MSE vs Validation MSE\")\n",
        "plt.xlabel(\"Iterations/Epoch\")\n",
        "plt.plot(history.history['mean_squared_error'], 'b')\n",
        "plt.plot(history.history['val_mean_squared_error'], 'g-.')\n",
        "plt.legend(['Training Loss','Validation Loss'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJs0LgaiisE8",
        "colab_type": "text"
      },
      "source": [
        "## Save Model - Download Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgmp1z9-d3dG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('modelt.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6AwrleFd3fy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('modelt.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h96IEGr8dbJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save('model6.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tp1Jk4TJVAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('model6.json')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
